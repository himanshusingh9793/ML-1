{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOp5r9EJwk4p"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xRUmcyvCJsem",
    "outputId": "1743d525-843b-4872-81e6-3257f2807bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/Multi_Label_Text_Classification')\n",
    "base_dir = 'gdrive/My Drive/Colab Notebooks/Multi_Label_Text_Classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izPpn887fH5Q"
   },
   "outputs": [],
   "source": [
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "!pip3 install --quiet tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T19:02:17.597554Z",
     "start_time": "2019-03-12T19:01:56.079763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pr_bmQWWaG9C",
    "outputId": "f4043085-e0ed-41e4-c307-44c8e47275df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import functools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import re\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=0.8)\n",
    "\n",
    "from helper_functions import *\n",
    "rdm_seed = 29\n",
    "np.random.seed(rdm_seed)\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMMMuhxHaG9j"
   },
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FmtyD9RgXRO"
   },
   "source": [
    "**Loading the input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T19:02:23.465051Z",
     "start_time": "2019-03-12T19:02:17.601558Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5OwlamR5aG9l"
   },
   "outputs": [],
   "source": [
    "#mydata_train = pd.read_csv('./../Data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "#mydata_test = pd.read_csv('./../Data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "#mydata = pd.read_csv('../Data/movies_genres.csv', delimiter='\\t')\n",
    "\n",
    "mydata_train = pd.read_csv(base_dir+'Data/preprocessed/movies_genres_train_preprocessed.csv')\n",
    "mydata_test = pd.read_csv(base_dir+'Data/preprocessed/movies_genres_test_preprocessed.csv')\n",
    "mydata = pd.read_csv(base_dir+'Data/movies_genres.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgC2z4bxaG9t"
   },
   "outputs": [],
   "source": [
    "train_X, train_y = mydata_train['plot'], mydata_train.drop(['title', 'plot', 'plot_lang'], axis=1)\n",
    "test_X, test_y = mydata_test['plot'], mydata_test.drop(['title', 'plot', 'plot_lang'], axis=1)\n",
    "\n",
    "category_columns = train_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5f4Bz2uaG-F"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zFCTARoBEUT"
   },
   "source": [
    "## Obtain Plot Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qA10A8tABC1l"
   },
   "outputs": [],
   "source": [
    "# embed_movie_plots(train_X, train_or_test='train')\n",
    "# embed_movie_plots(test_X, train_or_test='test')\n",
    "\n",
    "train_files = glob.glob(base_dir+\"Data/preprocessed/embed_vector/*train*.npy\")\n",
    "train_vector_set = []\n",
    "for file in train_files:\n",
    "  train_vector_set.append(np.load(file))\n",
    "train_vector = np.concatenate(train_vector_set)\n",
    "\n",
    "test_files = glob.glob(base_dir+\"Data/preprocessed/embed_vector/*test*.npy\")\n",
    "test_vector_set = []\n",
    "for file in test_files:\n",
    "    test_vector_set.append(np.load(file))\n",
    "test_vector = np.concatenate(test_vector_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bl9BTeBi_ppk"
   },
   "source": [
    "## LabelPowerset\n",
    "We use a Neural Network model to make prediction among one of the 1505 unique genre combinations in our training data set. \n",
    "* Input Layer consists of 512 features\n",
    "* Output Layer consists of 1505 nodes representing the each of the unique genre combinations  \n",
    "  * We use softmax activation function since the classifier has to output one among the 1505 combinations\n",
    "* Hidden Layers - number of nodes in the hidden layer has to be in between the number of input and output nodes for optimal performance. We select 1024 neurons\n",
    "* Dropout of 20%. To avoid overfit, we randomly drop out 20% of the neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSGCCgFIllbn"
   },
   "outputs": [],
   "source": [
    "# Creating a LUT for the 1505 labels\n",
    "train_y_labels= train_y.groupby(list(category_columns)).ngroup()\n",
    "y_labels_lut = train_y.copy(deep=True) \n",
    "y_labels_lut['Labels'] = train_y_labels\n",
    "y_labels_lut = y_labels_lut.drop_duplicates()\n",
    "y_labels_lut = y_labels_lut.reset_index(drop=True).set_index('Labels').sort_index()\n",
    "\n",
    "\n",
    "# One-hot encoding the output labels\n",
    "num_classes = y_labels_lut.shape[0]\n",
    "train_y_onehot = np_utils.to_categorical(train_y_labels, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7i9Ek6BljmP2"
   },
   "outputs": [],
   "source": [
    "def gen_model(optimizer):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(1024, activation='relu', input_shape=(512,)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1505, activation='softmax'))\n",
    "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdAgkkM63cX8"
   },
   "source": [
    "**Stochastic Gradient Descent Optimizer** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "mTb6N-RRyRLH",
    "outputId": "99ac19e9-01bf-45d5-d66c-93b0d38a6e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66060 samples, validate on 28312 samples\n",
      "Epoch 1/20\n",
      "66060/66060 [==============================] - 7s 102us/step - loss: 3.9901 - acc: 0.2305 - val_loss: 4.1950 - val_acc: 0.2662\n",
      "Epoch 2/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 3.3638 - acc: 0.3053 - val_loss: 4.1847 - val_acc: 0.2216\n",
      "Epoch 3/20\n",
      "66060/66060 [==============================] - 3s 47us/step - loss: 3.1510 - acc: 0.3252 - val_loss: 3.9117 - val_acc: 0.2974\n",
      "Epoch 4/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 3.0040 - acc: 0.3406 - val_loss: 4.3187 - val_acc: 0.2114\n",
      "Epoch 5/20\n",
      "66060/66060 [==============================] - 3s 45us/step - loss: 2.8901 - acc: 0.3538 - val_loss: 3.9322 - val_acc: 0.2812\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 6/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.7689 - acc: 0.3722 - val_loss: 3.8393 - val_acc: 0.2949\n",
      "Epoch 7/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.7187 - acc: 0.3798 - val_loss: 3.8948 - val_acc: 0.2949\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 8/20\n",
      "66060/66060 [==============================] - 4s 53us/step - loss: 2.6673 - acc: 0.3868 - val_loss: 3.8021 - val_acc: 0.3257\n",
      "Epoch 9/20\n",
      "66060/66060 [==============================] - 4s 53us/step - loss: 2.6446 - acc: 0.3893 - val_loss: 3.8411 - val_acc: 0.3102\n",
      "Epoch 10/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.6225 - acc: 0.3931 - val_loss: 3.8220 - val_acc: 0.3237\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 11/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.5993 - acc: 0.3973 - val_loss: 3.7905 - val_acc: 0.3294\n",
      "Epoch 12/20\n",
      "66060/66060 [==============================] - 3s 50us/step - loss: 2.5863 - acc: 0.3992 - val_loss: 3.7888 - val_acc: 0.3223\n",
      "Epoch 13/20\n",
      "66060/66060 [==============================] - 3s 49us/step - loss: 2.5798 - acc: 0.4006 - val_loss: 3.8016 - val_acc: 0.3298\n",
      "Epoch 14/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.5695 - acc: 0.4040 - val_loss: 3.8075 - val_acc: 0.3286\n",
      "Epoch 15/20\n",
      "66060/66060 [==============================] - 3s 53us/step - loss: 2.5606 - acc: 0.4050 - val_loss: 3.8184 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0625.\n",
      "Epoch 16/20\n",
      "66060/66060 [==============================] - 3s 49us/step - loss: 2.5459 - acc: 0.4056 - val_loss: 3.7993 - val_acc: 0.3278\n",
      "Epoch 17/20\n",
      "66060/66060 [==============================] - 4s 60us/step - loss: 2.5384 - acc: 0.4078 - val_loss: 3.8002 - val_acc: 0.3303\n",
      "Epoch 18/20\n",
      "66060/66060 [==============================] - 4s 61us/step - loss: 2.5356 - acc: 0.4080 - val_loss: 3.7963 - val_acc: 0.3307\n",
      "Epoch 19/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.5336 - acc: 0.4081 - val_loss: 3.8043 - val_acc: 0.3307\n",
      "Epoch 20/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 2.5272 - acc: 0.4088 - val_loss: 3.8053 - val_acc: 0.3230\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.03125.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa33589ff28>"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.SGD(lr=1))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "RCDXPSm81g1n",
    "outputId": "01b62137-f980-4043-ba4c-1e4c39757e9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.57</td>\n",
       "      <td>7320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.63</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg/Total</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>65440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precision  Recall  F1-Score  Support\n",
       "Action            0.80    0.31      0.45   4321.0\n",
       "Adult             0.00    0.00      0.00     11.0\n",
       "Adventure         0.77    0.28      0.41   3496.0\n",
       "Animation         0.79    0.58      0.67   3333.0\n",
       "Biography         0.47    0.02      0.04    354.0\n",
       "Comedy            0.71    0.48      0.57   7320.0\n",
       "Crime             0.80    0.55      0.65   4453.0\n",
       "Documentary       0.56    0.60      0.58   1863.0\n",
       "Drama             0.83    0.72      0.77  11067.0\n",
       "Family            0.78    0.31      0.45   4173.0\n",
       "Fantasy           0.79    0.26      0.39   2643.0\n",
       "Game-Show         0.79    0.24      0.36    450.0\n",
       "History           0.75    0.20      0.32    623.0\n",
       "Horror            0.54    0.05      0.09    854.0\n",
       "Music             0.63    0.28      0.39    654.0\n",
       "Musical           0.00    0.00      0.00    182.0\n",
       "Mystery           0.70    0.42      0.52   4114.0\n",
       "News              0.70    0.44      0.54    681.0\n",
       "Reality-TV        0.48    0.67      0.56   1748.0\n",
       "Romance           0.72    0.50      0.59   4581.0\n",
       "Sci-Fi            0.88    0.40      0.55   3055.0\n",
       "Short             0.00    0.00      0.00    142.0\n",
       "Sport             0.68    0.27      0.39    426.0\n",
       "Talk-Show         0.72    0.56      0.63    809.0\n",
       "Thriller          0.63    0.27      0.38   3254.0\n",
       "War               0.63    0.32      0.42    388.0\n",
       "Western           0.46    0.53      0.49    445.0\n",
       "Avg/Total         0.74    0.46      0.55  65440.0"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccnUR5zH3nvs"
   },
   "source": [
    "**Adam Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "5OGbBJRH3sWm",
    "outputId": "e262fbf0-f0d6-411a-d5ef-510f05aa4754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66060 samples, validate on 28312 samples\n",
      "Epoch 1/20\n",
      "66060/66060 [==============================] - 8s 123us/step - loss: 3.5918 - acc: 0.2856 - val_loss: 4.0147 - val_acc: 0.3155\n",
      "Epoch 2/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.8687 - acc: 0.3532 - val_loss: 4.0495 - val_acc: 0.3191\n",
      "Epoch 3/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.5983 - acc: 0.3825 - val_loss: 4.0961 - val_acc: 0.3256\n",
      "Epoch 4/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.4091 - acc: 0.4088 - val_loss: 4.1904 - val_acc: 0.3258\n",
      "Epoch 5/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.2701 - acc: 0.4288 - val_loss: 4.2636 - val_acc: 0.3278\n",
      "Epoch 6/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.1574 - acc: 0.4436 - val_loss: 4.3020 - val_acc: 0.3276\n",
      "Epoch 7/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.0586 - acc: 0.4617 - val_loss: 4.3686 - val_acc: 0.3262\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/20\n",
      "66060/66060 [==============================] - 4s 62us/step - loss: 1.9553 - acc: 0.4830 - val_loss: 4.3893 - val_acc: 0.3272\n",
      "Epoch 9/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 1.9030 - acc: 0.4906 - val_loss: 4.4073 - val_acc: 0.3256\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "66060/66060 [==============================] - 4s 67us/step - loss: 1.8524 - acc: 0.5026 - val_loss: 4.4250 - val_acc: 0.3306\n",
      "Epoch 11/20\n",
      "66060/66060 [==============================] - 4s 63us/step - loss: 1.8297 - acc: 0.5058 - val_loss: 4.4242 - val_acc: 0.3304\n",
      "Epoch 12/20\n",
      "66060/66060 [==============================] - 5s 70us/step - loss: 1.8122 - acc: 0.5097 - val_loss: 4.4439 - val_acc: 0.3272\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/20\n",
      "66060/66060 [==============================] - 4s 63us/step - loss: 1.7864 - acc: 0.5149 - val_loss: 4.4463 - val_acc: 0.3303\n",
      "Epoch 14/20\n",
      "66060/66060 [==============================] - 4s 59us/step - loss: 1.7762 - acc: 0.5155 - val_loss: 4.4552 - val_acc: 0.3305\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 15/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 1.7627 - acc: 0.5182 - val_loss: 4.4623 - val_acc: 0.3305\n",
      "Epoch 16/20\n",
      "66060/66060 [==============================] - 4s 60us/step - loss: 1.7584 - acc: 0.5193 - val_loss: 4.4653 - val_acc: 0.3308\n",
      "Epoch 17/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 1.7486 - acc: 0.5225 - val_loss: 4.4701 - val_acc: 0.3304\n",
      "Epoch 18/20\n",
      "66060/66060 [==============================] - 4s 61us/step - loss: 1.7456 - acc: 0.5222 - val_loss: 4.4710 - val_acc: 0.3308\n",
      "Epoch 19/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 1.7375 - acc: 0.5230 - val_loss: 4.4748 - val_acc: 0.3307\n",
      "Epoch 20/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 1.7312 - acc: 0.5257 - val_loss: 4.4834 - val_acc: 0.3298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa334b32588>"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.Adam(lr=0.001))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "B7RBqcxsxC0x",
    "outputId": "f8279ece-3142-4fdc-e3ec-91b9d03f2d43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.56</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.63</td>\n",
       "      <td>7320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>11067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>4114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.62</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg/Total</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>65440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precision  Recall  F1-Score  Support\n",
       "Action            0.80    0.43      0.56   4321.0\n",
       "Adult             0.50    0.09      0.15     11.0\n",
       "Adventure         0.80    0.41      0.54   3496.0\n",
       "Animation         0.82    0.64      0.72   3333.0\n",
       "Biography         0.59    0.16      0.25    354.0\n",
       "Comedy            0.73    0.56      0.63   7320.0\n",
       "Crime             0.82    0.60      0.69   4453.0\n",
       "Documentary       0.60    0.64      0.62   1863.0\n",
       "Drama             0.85    0.74      0.79  11067.0\n",
       "Family            0.79    0.40      0.53   4173.0\n",
       "Fantasy           0.79    0.41      0.54   2643.0\n",
       "Game-Show         0.88    0.35      0.50    450.0\n",
       "History           0.74    0.32      0.44    623.0\n",
       "Horror            0.68    0.20      0.31    854.0\n",
       "Music             0.71    0.39      0.50    654.0\n",
       "Musical           0.64    0.13      0.21    182.0\n",
       "Mystery           0.74    0.47      0.57   4114.0\n",
       "News              0.79    0.51      0.62    681.0\n",
       "Reality-TV        0.57    0.68      0.62   1748.0\n",
       "Romance           0.74    0.57      0.64   4581.0\n",
       "Sci-Fi            0.86    0.52      0.65   3055.0\n",
       "Short             0.65    0.08      0.14    142.0\n",
       "Sport             0.69    0.40      0.50    426.0\n",
       "Talk-Show         0.73    0.66      0.69    809.0\n",
       "Thriller          0.71    0.36      0.48   3254.0\n",
       "War               0.75    0.41      0.53    388.0\n",
       "Western           0.53    0.57      0.55    445.0\n",
       "Avg/Total         0.77    0.54      0.62  65440.0"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EAYp4Kt30A7"
   },
   "source": [
    "**RMSProp Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "lTLjU08R4AQW",
    "outputId": "0ca0f4e4-8fac-456a-ad21-b7e525b25251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66060 samples, validate on 28312 samples\n",
      "Epoch 1/20\n",
      "66060/66060 [==============================] - 8s 122us/step - loss: 3.5974 - acc: 0.2881 - val_loss: 4.1630 - val_acc: 0.3163\n",
      "Epoch 2/20\n",
      "66060/66060 [==============================] - 4s 60us/step - loss: 3.0975 - acc: 0.3473 - val_loss: 4.1794 - val_acc: 0.3240\n",
      "Epoch 3/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 2.9403 - acc: 0.3708 - val_loss: 4.1496 - val_acc: 0.3272\n",
      "Epoch 4/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.8348 - acc: 0.3841 - val_loss: 4.2127 - val_acc: 0.3277\n",
      "Epoch 5/20\n",
      "66060/66060 [==============================] - 3s 49us/step - loss: 2.7578 - acc: 0.3956 - val_loss: 4.2113 - val_acc: 0.3337\n",
      "Epoch 6/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.6958 - acc: 0.4071 - val_loss: 4.1122 - val_acc: 0.3310\n",
      "Epoch 7/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.6420 - acc: 0.4156 - val_loss: 4.2332 - val_acc: 0.3276\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.5630 - acc: 0.4295 - val_loss: 4.1771 - val_acc: 0.3319\n",
      "Epoch 9/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 2.5298 - acc: 0.4343 - val_loss: 4.2293 - val_acc: 0.3331\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "66060/66060 [==============================] - 3s 49us/step - loss: 2.4899 - acc: 0.4414 - val_loss: 4.2105 - val_acc: 0.3325\n",
      "Epoch 11/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 2.4711 - acc: 0.4455 - val_loss: 4.1985 - val_acc: 0.3326\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.4502 - acc: 0.4482 - val_loss: 4.1922 - val_acc: 0.3329\n",
      "Epoch 13/20\n",
      "66060/66060 [==============================] - 3s 50us/step - loss: 2.4404 - acc: 0.4491 - val_loss: 4.1945 - val_acc: 0.3342\n",
      "Epoch 14/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.4330 - acc: 0.4522 - val_loss: 4.1959 - val_acc: 0.3338\n",
      "Epoch 15/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.4226 - acc: 0.4528 - val_loss: 4.2121 - val_acc: 0.3330\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 16/20\n",
      "66060/66060 [==============================] - 4s 53us/step - loss: 2.4167 - acc: 0.4555 - val_loss: 4.1915 - val_acc: 0.3330\n",
      "Epoch 17/20\n",
      "66060/66060 [==============================] - 4s 62us/step - loss: 2.4136 - acc: 0.4559 - val_loss: 4.2169 - val_acc: 0.3319\n",
      "Epoch 18/20\n",
      "66060/66060 [==============================] - 4s 67us/step - loss: 2.4068 - acc: 0.4572 - val_loss: 4.2114 - val_acc: 0.3322\n",
      "Epoch 19/20\n",
      "66060/66060 [==============================] - 3s 50us/step - loss: 2.4007 - acc: 0.4596 - val_loss: 4.2096 - val_acc: 0.3313\n",
      "Epoch 20/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.3975 - acc: 0.4575 - val_loss: 4.2107 - val_acc: 0.3321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3358bb2e8>"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.RMSprop(lr=0.001))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "E7ard7-m3Zuk",
    "outputId": "6b6e7b63-82d3-4e0b-bd24-b9f8f0fc39f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>7320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.40</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.28</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.59</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg/Total</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "      <td>65440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precision  Recall  F1-Score  Support\n",
       "Action            0.81    0.22      0.35   4321.0\n",
       "Adult             0.00    0.00      0.00     11.0\n",
       "Adventure         0.81    0.20      0.32   3496.0\n",
       "Animation         0.78    0.53      0.63   3333.0\n",
       "Biography         0.64    0.03      0.05    354.0\n",
       "Comedy            0.70    0.50      0.58   7320.0\n",
       "Crime             0.79    0.54      0.64   4453.0\n",
       "Documentary       0.58    0.60      0.59   1863.0\n",
       "Drama             0.84    0.71      0.77  11067.0\n",
       "Family            0.84    0.22      0.35   4173.0\n",
       "Fantasy           0.85    0.16      0.27   2643.0\n",
       "Game-Show         0.84    0.26      0.40    450.0\n",
       "History           0.73    0.17      0.28    623.0\n",
       "Horror            0.53    0.02      0.04    854.0\n",
       "Music             0.66    0.27      0.38    654.0\n",
       "Musical           0.00    0.00      0.00    182.0\n",
       "Mystery           0.72    0.39      0.51   4114.0\n",
       "News              0.82    0.46      0.59    681.0\n",
       "Reality-TV        0.53    0.67      0.59   1748.0\n",
       "Romance           0.72    0.51      0.60   4581.0\n",
       "Sci-Fi            0.90    0.34      0.49   3055.0\n",
       "Short             0.00    0.00      0.00    142.0\n",
       "Sport             0.71    0.28      0.41    426.0\n",
       "Talk-Show         0.75    0.59      0.66    809.0\n",
       "Thriller          0.69    0.24      0.36   3254.0\n",
       "War               0.73    0.31      0.44    388.0\n",
       "Western           0.46    0.54      0.50    445.0\n",
       "Avg/Total         0.76    0.44      0.53  65440.0"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYs4930D4GH3"
   },
   "source": [
    "**Adagrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "u9IQXjT34amh",
    "outputId": "6b403241-56c5-4cf8-a855-b80894d89a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66060 samples, validate on 28312 samples\n",
      "Epoch 1/20\n",
      "66060/66060 [==============================] - 7s 108us/step - loss: 3.4526 - acc: 0.2994 - val_loss: 4.0305 - val_acc: 0.3140\n",
      "Epoch 2/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 3.0218 - acc: 0.3402 - val_loss: 4.0122 - val_acc: 0.3219\n",
      "Epoch 3/20\n",
      "66060/66060 [==============================] - 3s 48us/step - loss: 2.8571 - acc: 0.3558 - val_loss: 4.0240 - val_acc: 0.3222\n",
      "Epoch 4/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.7436 - acc: 0.3655 - val_loss: 4.0313 - val_acc: 0.3240\n",
      "Epoch 5/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 2.6594 - acc: 0.3750 - val_loss: 4.0504 - val_acc: 0.3262\n",
      "Epoch 6/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.5886 - acc: 0.3831 - val_loss: 4.0635 - val_acc: 0.3277\n",
      "Epoch 7/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.5309 - acc: 0.3905 - val_loss: 4.0898 - val_acc: 0.3283\n",
      "Epoch 8/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 2.4812 - acc: 0.3962 - val_loss: 4.0895 - val_acc: 0.3295\n",
      "Epoch 9/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 2.4379 - acc: 0.4018 - val_loss: 4.1129 - val_acc: 0.3293\n",
      "Epoch 10/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.3996 - acc: 0.4078 - val_loss: 4.1326 - val_acc: 0.3290\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 11/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 2.3661 - acc: 0.4102 - val_loss: 4.1357 - val_acc: 0.3290\n",
      "Epoch 12/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.3508 - acc: 0.4134 - val_loss: 4.1361 - val_acc: 0.3292\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 13/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 2.3336 - acc: 0.4149 - val_loss: 4.1470 - val_acc: 0.3293\n",
      "Epoch 14/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.3277 - acc: 0.4180 - val_loss: 4.1473 - val_acc: 0.3289\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 15/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.3207 - acc: 0.4176 - val_loss: 4.1505 - val_acc: 0.3297\n",
      "Epoch 16/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.3173 - acc: 0.4183 - val_loss: 4.1510 - val_acc: 0.3300\n",
      "Epoch 17/20\n",
      "66060/66060 [==============================] - 4s 60us/step - loss: 2.3181 - acc: 0.4180 - val_loss: 4.1528 - val_acc: 0.3304\n",
      "Epoch 18/20\n",
      "66060/66060 [==============================] - 4s 61us/step - loss: 2.3140 - acc: 0.4175 - val_loss: 4.1544 - val_acc: 0.3298\n",
      "Epoch 19/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 2.3088 - acc: 0.4196 - val_loss: 4.1570 - val_acc: 0.3294\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 20/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.3069 - acc: 0.4193 - val_loss: 4.1568 - val_acc: 0.3297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa334de9be0>"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.Adagrad(lr=0.01))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "Du7Q_rdo4i9n",
    "outputId": "67d26dcd-4e2f-41c6-adc6-0ee9738eab10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>7320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.45</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.35</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.41</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg/Total</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.56</td>\n",
       "      <td>65440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precision  Recall  F1-Score  Support\n",
       "Action            0.81    0.34      0.47   4321.0\n",
       "Adult             0.00    0.00      0.00     11.0\n",
       "Adventure         0.78    0.30      0.43   3496.0\n",
       "Animation         0.81    0.59      0.68   3333.0\n",
       "Biography         0.65    0.09      0.15    354.0\n",
       "Comedy            0.71    0.50      0.59   7320.0\n",
       "Crime             0.80    0.56      0.66   4453.0\n",
       "Documentary       0.55    0.61      0.58   1863.0\n",
       "Drama             0.84    0.72      0.77  11067.0\n",
       "Family            0.78    0.29      0.42   4173.0\n",
       "Fantasy           0.79    0.28      0.41   2643.0\n",
       "Game-Show         0.84    0.31      0.45    450.0\n",
       "History           0.70    0.23      0.35    623.0\n",
       "Horror            0.65    0.09      0.16    854.0\n",
       "Music             0.64    0.30      0.41    654.0\n",
       "Musical           1.00    0.02      0.03    182.0\n",
       "Mystery           0.72    0.42      0.53   4114.0\n",
       "News              0.73    0.47      0.57    681.0\n",
       "Reality-TV        0.51    0.65      0.57   1748.0\n",
       "Romance           0.70    0.52      0.60   4581.0\n",
       "Sci-Fi            0.89    0.42      0.57   3055.0\n",
       "Short             1.00    0.02      0.04    142.0\n",
       "Sport             0.68    0.32      0.44    426.0\n",
       "Talk-Show         0.70    0.61      0.65    809.0\n",
       "Thriller          0.66    0.27      0.39   3254.0\n",
       "War               0.68    0.34      0.45    388.0\n",
       "Western           0.47    0.54      0.50    445.0\n",
       "Avg/Total         0.76    0.47      0.56  65440.0"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkPN7fsX4le8"
   },
   "source": [
    "**Adadelta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "s71_8CW04pP-",
    "outputId": "48090c9c-aee9-4d7a-9398-abb10ef0a755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66060 samples, validate on 28312 samples\n",
      "Epoch 1/20\n",
      "66060/66060 [==============================] - 8s 119us/step - loss: 4.1434 - acc: 0.2323 - val_loss: 4.2003 - val_acc: 0.2540\n",
      "Epoch 2/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 3.4743 - acc: 0.3014 - val_loss: 3.9971 - val_acc: 0.2782\n",
      "Epoch 3/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 3.2853 - acc: 0.3222 - val_loss: 3.9030 - val_acc: 0.3040\n",
      "Epoch 4/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 3.1600 - acc: 0.3346 - val_loss: 3.8465 - val_acc: 0.3054\n",
      "Epoch 5/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 3.0633 - acc: 0.3467 - val_loss: 3.8012 - val_acc: 0.3178\n",
      "Epoch 6/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 2.9848 - acc: 0.3511 - val_loss: 3.8122 - val_acc: 0.3037\n",
      "Epoch 7/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.9268 - acc: 0.3609 - val_loss: 3.7699 - val_acc: 0.3188\n",
      "Epoch 8/20\n",
      "66060/66060 [==============================] - 4s 56us/step - loss: 2.8725 - acc: 0.3669 - val_loss: 3.7406 - val_acc: 0.3223\n",
      "Epoch 9/20\n",
      "66060/66060 [==============================] - 4s 61us/step - loss: 2.8281 - acc: 0.3708 - val_loss: 3.7762 - val_acc: 0.3116\n",
      "Epoch 10/20\n",
      "66060/66060 [==============================] - 4s 54us/step - loss: 2.7867 - acc: 0.3782 - val_loss: 3.8571 - val_acc: 0.2673\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "Epoch 11/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 2.7397 - acc: 0.3884 - val_loss: 3.7566 - val_acc: 0.3264\n",
      "Epoch 12/20\n",
      "66060/66060 [==============================] - 4s 55us/step - loss: 2.7214 - acc: 0.3896 - val_loss: 3.7559 - val_acc: 0.3294\n",
      "Epoch 13/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 2.7041 - acc: 0.3944 - val_loss: 3.7371 - val_acc: 0.3304\n",
      "Epoch 14/20\n",
      "66060/66060 [==============================] - 4s 60us/step - loss: 2.6919 - acc: 0.3954 - val_loss: 3.7630 - val_acc: 0.3220\n",
      "Epoch 15/20\n",
      "66060/66060 [==============================] - 4s 64us/step - loss: 2.6786 - acc: 0.3986 - val_loss: 3.7538 - val_acc: 0.3284\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "Epoch 16/20\n",
      "66060/66060 [==============================] - 4s 65us/step - loss: 2.6593 - acc: 0.4027 - val_loss: 3.7477 - val_acc: 0.3294\n",
      "Epoch 17/20\n",
      "66060/66060 [==============================] - 4s 62us/step - loss: 2.6515 - acc: 0.4043 - val_loss: 3.7593 - val_acc: 0.3314\n",
      "Epoch 18/20\n",
      "66060/66060 [==============================] - 4s 58us/step - loss: 2.6411 - acc: 0.4076 - val_loss: 3.7596 - val_acc: 0.3284\n",
      "Epoch 19/20\n",
      "66060/66060 [==============================] - 4s 61us/step - loss: 2.6385 - acc: 0.4081 - val_loss: 3.7561 - val_acc: 0.3303\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "Epoch 20/20\n",
      "66060/66060 [==============================] - 4s 57us/step - loss: 2.6267 - acc: 0.4107 - val_loss: 3.7620 - val_acc: 0.3311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa334b1f550>"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model(keras.optimizers.Adadelta(lr=1.0))\n",
    "model.fit(train_vector, train_y_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "7JtYj2QS4qcN",
    "outputId": "ec2421da-ce92-4f55-a4c5-4c45b0951a19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>7320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>4173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.55</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg/Total</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>65440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precision  Recall  F1-Score  Support\n",
       "Action            0.81    0.28      0.42   4321.0\n",
       "Adult             0.00    0.00      0.00     11.0\n",
       "Adventure         0.77    0.25      0.38   3496.0\n",
       "Animation         0.80    0.58      0.67   3333.0\n",
       "Biography         0.53    0.03      0.05    354.0\n",
       "Comedy            0.71    0.49      0.58   7320.0\n",
       "Crime             0.80    0.54      0.65   4453.0\n",
       "Documentary       0.57    0.58      0.58   1863.0\n",
       "Drama             0.84    0.71      0.77  11067.0\n",
       "Family            0.77    0.26      0.39   4173.0\n",
       "Fantasy           0.80    0.24      0.37   2643.0\n",
       "Game-Show         0.79    0.23      0.36    450.0\n",
       "History           0.73    0.20      0.32    623.0\n",
       "Horror            0.60    0.06      0.11    854.0\n",
       "Music             0.65    0.28      0.39    654.0\n",
       "Musical           0.00    0.00      0.00    182.0\n",
       "Mystery           0.72    0.40      0.51   4114.0\n",
       "News              0.72    0.44      0.55    681.0\n",
       "Reality-TV        0.49    0.68      0.57   1748.0\n",
       "Romance           0.72    0.50      0.59   4581.0\n",
       "Sci-Fi            0.89    0.38      0.54   3055.0\n",
       "Short             1.00    0.01      0.01    142.0\n",
       "Sport             0.67    0.29      0.40    426.0\n",
       "Talk-Show         0.72    0.61      0.66    809.0\n",
       "Thriller          0.63    0.27      0.38   3254.0\n",
       "War               0.65    0.31      0.42    388.0\n",
       "Western           0.49    0.53      0.51    445.0\n",
       "Avg/Total         0.75    0.45      0.54  65440.0"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "y_pred_label = pd.DataFrame(np.argmax(y_pred, axis=1))\n",
    "predictions = pd.merge(y_pred_label, y_labels_lut, how='left', left_on=0, right_on='Labels')[category_columns]\n",
    "accuracy(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFFX2mfg77jG"
   },
   "source": [
    "**Observations/Conclusions**\n",
    "* Predictions using Sentence Embedding with Neural Networks doesnt really produce predictions as accurate as the simple ML models which used TF-IDF vectorizer\n",
    "* Adam Optimizer seems to perform best among the ones tried with a F1 score of 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjhC10wSyRTv"
   },
   "source": [
    "## Binary Relevance\n",
    "Here we build an predictor for each genre separately. In other words, the output layer will have 28 nodes - each corresponding to a genre. We will use a threshold for each genre to make predictions whether the plot falls into that genre or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "d_IAp7yayRZt",
    "outputId": "f503c61f-b02d-4cb3-9bf6-0858a6471a08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Action         0.085343\n",
       "Adult          0.000530\n",
       "Adventure      0.071494\n",
       "Animation      0.085152\n",
       "Biography      0.010925\n",
       "Comedy         0.281333\n",
       "Crime          0.113042\n",
       "Documentary    0.107627\n",
       "Drama          0.369008\n",
       "Family         0.119008\n",
       "Fantasy        0.047260\n",
       "Game-Show      0.016901\n",
       "History        0.021606\n",
       "Horror         0.018194\n",
       "Music          0.023132\n",
       "Musical        0.004376\n",
       "Mystery        0.083838\n",
       "News           0.034587\n",
       "Reality-TV     0.112194\n",
       "Romance        0.154633\n",
       "Sci-Fi         0.059371\n",
       "Short          0.004620\n",
       "Sport          0.016096\n",
       "Talk-Show      0.047090\n",
       "Thriller       0.059318\n",
       "War            0.010798\n",
       "Western        0.024541\n",
       "dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_thresh = (train_y.sum()/train_y.shape[0]).clip(upper=0.5)\n",
    "prob_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkU3QtzKyRiR"
   },
   "outputs": [],
   "source": [
    "def gen_model_genre(optimizer):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(800, activation='relu', input_shape=(512,)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Dense(27, activation='sigmoid'))\n",
    "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "rcARuSaRySfd",
    "outputId": "e7c1228f-3df9-4312-ede1-d3bc58d707cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66060 samples, validate on 28312 samples\n",
      "Epoch 1/20\n",
      "66060/66060 [==============================] - 7s 111us/step - loss: 4.1523 - acc: 0.3992 - val_loss: 4.0094 - val_acc: 0.4260\n",
      "Epoch 2/20\n",
      "66060/66060 [==============================] - 3s 42us/step - loss: 3.8093 - acc: 0.4505 - val_loss: 3.9495 - val_acc: 0.4530\n",
      "Epoch 3/20\n",
      "66060/66060 [==============================] - 3s 46us/step - loss: 3.7300 - acc: 0.4607 - val_loss: 3.9291 - val_acc: 0.4737\n",
      "Epoch 4/20\n",
      "66060/66060 [==============================] - 3s 43us/step - loss: 3.6728 - acc: 0.4686 - val_loss: 3.9294 - val_acc: 0.4549\n",
      "Epoch 5/20\n",
      "66060/66060 [==============================] - 3s 44us/step - loss: 3.6252 - acc: 0.4727 - val_loss: 3.9077 - val_acc: 0.4671\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 3.5749 - acc: 0.4810 - val_loss: 3.8965 - val_acc: 0.4675\n",
      "Epoch 7/20\n",
      "66060/66060 [==============================] - 3s 48us/step - loss: 3.5507 - acc: 0.4819 - val_loss: 3.9104 - val_acc: 0.4710\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "66060/66060 [==============================] - 3s 49us/step - loss: 3.5284 - acc: 0.4852 - val_loss: 3.9031 - val_acc: 0.4638\n",
      "Epoch 9/20\n",
      "66060/66060 [==============================] - 3s 43us/step - loss: 3.5191 - acc: 0.4869 - val_loss: 3.8913 - val_acc: 0.4690\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/20\n",
      "66060/66060 [==============================] - 3s 43us/step - loss: 3.5053 - acc: 0.4896 - val_loss: 3.8911 - val_acc: 0.4638\n",
      "Epoch 11/20\n",
      "66060/66060 [==============================] - 3s 41us/step - loss: 3.5000 - acc: 0.4911 - val_loss: 3.8981 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 12/20\n",
      "66060/66060 [==============================] - 3s 46us/step - loss: 3.4932 - acc: 0.4885 - val_loss: 3.8978 - val_acc: 0.4661\n",
      "Epoch 13/20\n",
      "66060/66060 [==============================] - 3s 51us/step - loss: 3.4903 - acc: 0.4902 - val_loss: 3.8959 - val_acc: 0.4683\n",
      "Epoch 14/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 3.4866 - acc: 0.4924 - val_loss: 3.8975 - val_acc: 0.4642\n",
      "Epoch 15/20\n",
      "66060/66060 [==============================] - 3s 47us/step - loss: 3.4824 - acc: 0.4906 - val_loss: 3.8968 - val_acc: 0.4693\n",
      "Epoch 16/20\n",
      "66060/66060 [==============================] - 3s 47us/step - loss: 3.4797 - acc: 0.4928 - val_loss: 3.8984 - val_acc: 0.4698\n",
      "Epoch 17/20\n",
      "66060/66060 [==============================] - 3s 41us/step - loss: 3.4757 - acc: 0.4937 - val_loss: 3.9002 - val_acc: 0.4666\n",
      "Epoch 18/20\n",
      "66060/66060 [==============================] - 3s 42us/step - loss: 3.4741 - acc: 0.4926 - val_loss: 3.9003 - val_acc: 0.4671\n",
      "Epoch 19/20\n",
      "66060/66060 [==============================] - 3s 52us/step - loss: 3.4681 - acc: 0.4940 - val_loss: 3.9015 - val_acc: 0.4685\n",
      "Epoch 20/20\n",
      "66060/66060 [==============================] - 3s 49us/step - loss: 3.4677 - acc: 0.4966 - val_loss: 3.8967 - val_acc: 0.4644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa334232d68>"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs, batch_size = 20, 128\n",
    "model = gen_model_genre(keras.optimizers.Adam(lr=0.001))\n",
    "model.fit(train_vector, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[lr_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "DCm_JADTyStj",
    "outputId": "6e163841-7f2a-4913-e023-97012c57bac5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biography</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>4173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.34</td>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.46</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musical</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.10</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>4114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reality-TV</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sci-Fi</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talk-Show</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>3254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.37</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.43</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg/Total</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>65440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precision  Recall  F1-Score  Support\n",
       "Action            0.59    0.58      0.58   4321.0\n",
       "Adult             0.01    0.64      0.03     11.0\n",
       "Adventure         0.55    0.67      0.60   3496.0\n",
       "Animation         0.69    0.80      0.74   3333.0\n",
       "Biography         0.12    0.61      0.20    354.0\n",
       "Comedy            0.76    0.23      0.35   7320.0\n",
       "Crime             0.73    0.64      0.68   4453.0\n",
       "Documentary       0.57    0.64      0.61   1863.0\n",
       "Drama             0.82    0.09      0.16  11067.0\n",
       "Family            0.64    0.51      0.57   4173.0\n",
       "Fantasy           0.46    0.68      0.55   2643.0\n",
       "Game-Show         0.47    0.72      0.57    450.0\n",
       "History           0.30    0.66      0.41    623.0\n",
       "Horror            0.24    0.61      0.34    854.0\n",
       "Music             0.36    0.63      0.46    654.0\n",
       "Musical           0.05    0.57      0.10    182.0\n",
       "Mystery           0.59    0.54      0.56   4114.0\n",
       "News              0.44    0.75      0.55    681.0\n",
       "Reality-TV        0.60    0.61      0.61   1748.0\n",
       "Romance           0.74    0.28      0.40   4581.0\n",
       "Sci-Fi            0.57    0.72      0.63   3055.0\n",
       "Short             0.03    0.37      0.05    142.0\n",
       "Sport             0.30    0.70      0.42    426.0\n",
       "Talk-Show         0.55    0.73      0.63    809.0\n",
       "Thriller          0.45    0.60      0.51   3254.0\n",
       "War               0.25    0.71      0.37    388.0\n",
       "Western           0.32    0.68      0.43    445.0\n",
       "Avg/Total         0.64    0.47      0.47  65440.0"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_vector)\n",
    "predictions = pd.DataFrame(index=test_y.index, columns=test_y.columns)\n",
    "for i in range(y_pred.shape[0]):\n",
    "  predictions.iloc[i,:] = (y_pred[i,:]>prob_thresh).map({True:1, False:0})\n",
    "accuracy(test_y, predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5_Modeling_Embedding_Neural_Net.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
